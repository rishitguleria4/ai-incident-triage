# ğŸ§  AI Incident Triage System

A productionâ€‘style, endâ€‘toâ€‘end **asynchronous AIâ€‘powered incident triage platform** built from scratch.

This system accepts incident reports, stores them safely, queues them for background processing, enriches them using a **local LLM (Phiâ€‘3 via Ollama)**, and displays the results in a clean web UI.

It is intentionally designed using real backend architecture patterns used in industry:

* Control plane vs Worker plane
* Asynchronous queues
* Faultâ€‘tolerant processing
* Background AI enrichment
* Local model inference

---

## ğŸš€ What This Project Demonstrates

* Fullâ€‘stack system design
* Async job processing with Redis + BullMQ
* PostgreSQL as source of truth
* Background worker architecture
* Local LLM integration (Ollama + Phiâ€‘3 Mini)
* Graceful degradation when AI is unavailable
* Simple APIâ€‘key authentication
* Frontend polling + realâ€‘time updates

This is **not** a chatbot.
This is an **AIâ€‘backed infrastructure service**.

---

## ğŸ§© Architecture Overview

```
Browser (React)
   |
   v
Backend API (Express)
   |
   +--> PostgreSQL  (persistent storage)
   |
   +--> Redis Queue (BullMQ)
             |
             v
         Worker Service
             |
             v
       Ollama (Phiâ€‘3 Mini)
```

### Control Plane

* Frontend
* Backend API

### Data Plane

* Redis
* Worker
* PostgreSQL
* Ollama

---

## ğŸ“¦ Tech Stack

| Layer             | Technology        |
| ----------------- | ----------------- |
| Frontend          | React + Vite      |
| Backend API       | Node.js + Express |
| Worker            | Node.js + BullMQ  |
| Queue             | Redis             |
| Database          | PostgreSQL        |
| AI Model          | Phiâ€‘3 Mini        |
| LLM Runtime       | Ollama            |
| Auth              | API Key Header    |
| Container Runtime | Docker            |

---

## âœ¨ Features

* Submit incident reports
* Input validation
* APIâ€‘key authentication
* Incident status lifecycle

  * submitted
  * processing
  * triaged
  * failed
* Background AI summarization
* Automatic retries
* Graceful failure handling
* Realâ€‘time UI updates

---

## ğŸ—‚ Folder Structure

```
ai-incident-system/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ index.js
â”‚       â”œâ”€â”€ db.js
â”‚       â”œâ”€â”€ queue.js
â”‚       â””â”€â”€ auth.js
â”‚
â”œâ”€â”€ worker/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ index.js
â”‚       â””â”€â”€ db.js
â”‚
â”œâ”€â”€ frontend/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ App.jsx
â”‚       â””â”€â”€ main.jsx
â”‚
â””â”€â”€ docker-compose.yml
```

---

## ğŸ” Data Flow (Critical)

```
User Submit
 â†’ Backend validates
 â†’ Backend inserts into DB
 â†’ Backend enqueues job
 â†’ Worker consumes job
 â†’ Worker calls Ollama
 â†’ Worker updates DB
 â†’ Frontend polls and displays
```

---

## ğŸ” Authentication

Every request must include:

```
X-API-KEY: secret123
```

Prevents unauthorized access.

---

## ğŸ›  Prerequisites

* Node.js 18+
* Docker
* Docker Compose
* Git
* Linux / macOS / WSL recommended

---

## ğŸ³ Start Infrastructure

```
docker compose up -d
```

Starts:

* PostgreSQL
* Redis

---

## ğŸ“¥ Install Dependencies

### Backend

```
cd backend
npm install
```

### Worker

```
cd worker
npm install
```

### Frontend

```
cd frontend
npm install
```

---

## â–¶ï¸ Run Services

Open **separate terminals**.

### Backend

```
cd backend
npm run dev
```

### Worker

```
cd worker
npm run dev
```

### Frontend

```
cd frontend
npm run dev
```

Frontend URL:

```
http://localhost:5173
```

---

## ğŸ§  Install Ollama

```
curl -fsSL https://ollama.com/install.sh | sh
```

Pull model:

```
ollama pull phi3:mini
```

Run Ollama:

```
ollama serve
```

---

## âœ… Verify Ollama

```
ollama run phi3:mini "hello"
```

API test:

```
curl http://localhost:11434/api/generate \
  -d '{
    "model": "phi3:mini",
    "prompt": "hello",
    "stream": false
  }'
```

---

## ğŸ§ª Submit Test Incident

```
curl -X POST http://localhost:4000/incidents \
  -H "Content-Type: application/json" \
  -H "x-api-key: secret123" \
  -d '{"title":"Disk Full","description":"Production disk at 100%"}'
```

Then visit UI.

---

## ğŸ“Š Incident Status Meanings

| Status     | Meaning                    |
| ---------- | -------------------------- |
| submitted  | Stored, waiting for worker |
| processing | Worker picked job          |
| triaged    | AI summary completed       |
| failed     | AI call failed             |

---

## âš™ Fault Tolerance

If Ollama is offline:

* Incidents still stored
* Worker marks status = failed
* System remains usable

AI is an optional enrichment, not a hard dependency.

---

## ğŸŒ Remote Access (Tunneling)

To allow a reviewer to access your system remotely, use tunneling.

### Option A â€” Ngrok

Install:

```
sudo snap install ngrok
```

Authenticate:

```
ngrok config add-authtoken <YOUR_TOKEN>
```

Expose frontend:

```
ngrok http 5173
```

Expose backend:

```
ngrok http 4000
```

Share the generated URLs.

---

### Option B â€” Cloudflared (Recommended)

Install:

```
sudo apt install cloudflared
```

Expose frontend:

```
cloudflared tunnel --url http://localhost:5173
```

Expose backend:

```
cloudflared tunnel --url http://localhost:4000
```

No account required.

---

## ğŸ§­ What Was Built (Stepâ€‘byâ€‘Step)

1. Designed architecture
2. Built backend API
3. Added PostgreSQL
4. Added Redis queue
5. Added worker
6. Implemented async jobs
7. Added status lifecycle
8. Added validation
9. Added authentication
10. Built frontend UI
11. Integrated Ollama
12. Integrated Phiâ€‘3 Mini
13. Promptâ€‘controlled output
14. Failure handling
15. Remote tunneling support

---

## ğŸ— Engineering Principles Used

* Separation of concerns
* Single source of truth
* Asynchronous processing
* Graceful degradation
* Idempotent updates
* Minimal coupling

---

## ğŸ”® Possible Future Extensions

* Structured JSON output
* Severity classification
* Category tagging
* Roleâ€‘based auth
* WebSockets instead of polling
* Metrics dashboard
* Model hotâ€‘swap

---

## ğŸ Final Note

This project mirrors how real internal tooling is built inside production companies.

It proves the author understands **systems**, not just frameworks.

---

**Built with intent, not tutorials.**
